import SwiftUI
import FaceAISDK_Core
import AVFoundation

/**
 * 1:1 äººè„¸è¯†åˆ«+æ´»ä½“æ£€æµ‹
 */
struct VerifyFaceView: View {
    // ç¡®ä¿ViewModelçš„ç”Ÿå‘½å‘¨æœŸä¸Žè§†å›¾ä¸€è‡´
    @StateObject private var viewModel: VerifyFaceModel = VerifyFaceModel()
    @Environment(\.dismiss) private var dismiss
    @State private var showLightHighDialog = false
    @State private var showToast = false
    @State private var toastViewTips: String = ""
    
    var autoControlBrightness: Bool = true

    // ä¸šåŠ¡å‚æ•°
    let faceID: String
    let threshold: Float
    
    //0.æ— éœ€æ´»ä½“æ£€æµ‹ 1.ä»…ä»…åŠ¨ä½œ 2.åŠ¨ä½œ+ç‚«å½© 3.ç‚«å½©
    let livenessType:Int
    //åŠ¨ä½œæ´»ä½“ç§ç±»ï¼š1. å¼ å¼ å˜´  2.å¾®ç¬‘  3.çœ¨çœ¨çœ¼  4.æ‘‡æ‘‡å¤´  5.ç‚¹å¤´
    let motionLiveness:String
    
    let motionLivenessTimeOut:Int  //æ—¶é—´ä¸ºç§’
    let motionLivenessSteps:Int    //åŠ¨ä½œæ´»ä½“ä¸ªæ•°
    
    let onDismiss: (Int) -> Void 

    // å¤šè¯­è¨€æç¤º
    private func localizedTip(for code: Int) -> String {
        let key = "Face_Tips_Code_\(code)"
        let defaultValue = "VerifyFace Tips Code=\(code)"
        return NSLocalizedString(key, value: defaultValue, comment: "")
    }
    
    // MARK: - Helper Methods

    /// Capture current frame from camera session for attendance
    private func captureAttendanceImage() {
        guard let captureSession = viewModel.captureSession else {
            print("âš ï¸ No capture session available")
            return
        }

        // Find video output
        guard let videoOutput = captureSession.outputs.first(where: { $0 is AVCaptureVideoDataOutput }) as? AVCaptureVideoDataOutput else {
            print("âš ï¸ No video output found")

            // Fallback: try to capture from camera connection
            captureFromCameraConnection(captureSession)
            return
        }

        print("ðŸ“¸ Attempting to capture frame from video output...")
        // Note: Direct frame capture requires delegate setup
        // For now, we'll use connection-based capture
        captureFromCameraConnection(captureSession)
    }

    /// Fallback method to capture from camera connection
    private func captureFromCameraConnection(_ session: AVCaptureSession) {
        // Get photo output if available
        if let photoOutput = session.outputs.first(where: { $0 is AVCapturePhotoOutput }) as? AVCapturePhotoOutput {
            let settings = AVCapturePhotoSettings()
            // Note: This requires AVCapturePhotoCaptureDelegate which we don't have access to
            print("â„¹ï¸ Photo output available but requires delegate setup")
        }

        // Alternative: Capture from preview layer (if accessible)
        print("â„¹ï¸ Frame capture would require SDK to expose captured image")
        print("â„¹ï¸ For full implementation, SDK needs to provide captured frame callback")
    }

    var body: some View {
        ZStack {
            VStack {
                 HStack {
                    Button(action: {
                        onDismiss(0) // 0 ä»£è¡¨ç”¨æˆ·å–æ¶ˆ
                        dismiss()
                    }) {
                        Image(systemName: "chevron.left")
                            .font(.system(size: 16, weight: .semibold))
                            .foregroundColor(.black)
                            .padding(10)
                            .background(Color.gray.opacity(0.1))
                            .clipShape(Circle())
                    }
                    Spacer()
                }
                .padding(.horizontal, 2)
                .padding(.top, 10)
                
                 Text(localizedTip(for: viewModel.sdkInterfaceTips.code))
                    .font(.system(size: 20).bold())
                    .padding(.horizontal, 20)
                    .padding(.vertical, 8)
                    .foregroundColor(.white)
                    .background(Color.brown)
                    .cornerRadius(20)
                
                Text(localizedTip(for: viewModel.sdkInterfaceTipsExtra.code))
                    .font(.system(size: 19).bold())
                    .padding(.bottom, 6)
                    .frame(minHeight: 30)
                    .foregroundColor(.black)
                
                FaceAICameraView(session: viewModel.captureSession, cameraSize: FaceCameraSize)
                    .frame(
                        width: FaceCameraSize,
                        height: FaceCameraSize
                    )
                    .padding(.vertical, 8)
                    .aspectRatio(1.0, contentMode: .fit)
                    .clipShape(Circle())
                    .overlay(Circle().stroke(Color.gray, lineWidth: 1))

                Spacer()
            }
            .padding()
            .frame(maxWidth: .infinity, maxHeight: .infinity)
            .background(viewModel.colorFlash.ignoresSafeArea())
            //éšè—ç³»ç»Ÿå¯¼èˆªæ 
            .navigationBarBackButtonHidden(true)
            .navigationBarHidden(true)
            if showToast {
                // è®¡ç®—æ˜¾ç¤ºå†…å®¹
                let similarity = String(format: "%.2f", viewModel.faceVerifyResult.similarity)
                // ä¼˜å…ˆä½¿ç”¨æ‰‹åŠ¨è®¾ç½®çš„ toastViewTips (ç”¨äºŽå¤„ç†æ— ç‰¹å¾å€¼çš„æƒ…å†µ)ï¼Œå¦åˆ™ä½¿ç”¨ SDK è¿”å›žçš„ tips
                let displayTips = toastViewTips.isEmpty ? viewModel.faceVerifyResult.tips : toastViewTips
                let displayMessage = (toastViewTips.isEmpty) ? "\(displayTips) \(similarity)" : displayTips
                
                // è®¡ç®—æ ·å¼ï¼šå¦‚æžœæ˜¯æ— ç‰¹å¾å€¼é”™è¯¯ï¼Œæˆ–è€…ç›¸ä¼¼åº¦ä½Žï¼Œåˆ™ä¸º failure
                let isSuccess = viewModel.faceVerifyResult.similarity > threshold && toastViewTips.isEmpty
                let toastStyle: ToastStyle = isSuccess ? .success : .failure
                
                VStack {
                    Spacer()
                    CustomToastView(
                        message: displayMessage,
                        style: toastStyle
                    )
                    .padding(.bottom, 77)
                }
                .frame(maxWidth: .infinity, maxHeight: .infinity)
                .transition(.move(edge: .bottom).combined(with: .opacity))
                .zIndex(1)
            }
            
            // --- é¡¶å±‚ï¼šå…‰çº¿è¿‡å¼ºè‡ªå®šä¹‰å¼¹çª— (Dialog) ---
            if showLightHighDialog {
                ZStack {
                    VStack(spacing: 22) {
                        Text(viewModel.faceVerifyResult.tips)
                            .font(.system(size: 16).bold())
                            .fontWeight(.semibold)
                            .multilineTextAlignment(.center)
                            .foregroundColor(.black)
                            .padding(.horizontal,25)


                        if let uiImage = UIImage.fromPluginBundle(named: "light_too_high") {
                                    Image(uiImage: uiImage)
                                        .resizable()
                                        .scaledToFit()
                                        .frame(maxHeight: 120)
                                        .padding(.horizontal,1)}
                        
                        Button(action: {
                            withAnimation {
                                showLightHighDialog = false
                                onDismiss(viewModel.faceVerifyResult.code)
                                dismiss()
                            }
                        }) {
                            Text("Confirm")
                                .font(.system(size: 18).bold())
                                .foregroundColor(.white)
                                .frame(maxWidth: .infinity)
                                .padding(.vertical, 10)
                                .background(Color.brown)
                                .cornerRadius(10)
                        }
                        .padding(.horizontal, 30)
                    }
                    .padding(.vertical, 22)
                    .background(Color.white)
                    .cornerRadius(20)
                    .shadow(color: Color.black.opacity(0.2), radius: 20, x: 0, y: 10)
                    .padding(.horizontal, 30) // è®¾ç½®å¼¹çª—å·¦å³è¾¹è·
                }
                .zIndex(2)
                .transition(.scale(scale: 0.8).combined(with: .opacity)) // æ·»åŠ å‡ºçŽ°åŠ¨ç”»
            }
        }
         .onAppear {
             if autoControlBrightness {
                 ScreenBrightnessHelper.shared.maximizeBrightness()
             }
             
             withAnimation(.easeInOut(duration: 0.3)) {
                UIScreen.main.brightness = 1.0
            }
            
            // æ ¡éªŒæœ¬åœ°æ˜¯å¦æœ‰ç‰¹å¾å€¼
            guard let faceFeature = UserDefaults.standard.string(forKey: faceID) else {
                toastViewTips = "No Face Feature for key: \(faceID)"
                showToast = true
                
                DispatchQueue.main.asyncAfter(deadline: .now() + 1.5) {
                    showToast = false
                    // å‡è®¾ VerifyResultCode.NO_FACE_FEATURE æ˜¯ 6 (å‚è€ƒæ³¨é‡Š)
                    onDismiss(6)
                    dismiss()
                }
                return
            }
            
            viewModel.initFaceAISDK(
                faceIDFeature: faceFeature,
                threshold: threshold,
                livenessType: livenessType,
                onlyLiveness: false,
                motionLiveness: motionLiveness,
                motionLivenessTimeOut:motionLivenessTimeOut,
                motionLivenessSteps:motionLivenessSteps
            )
        }
        .onChange(of: viewModel.faceVerifyResult.code) { newValue in
            // æ¸…ç©ºæ‰‹åŠ¨çš„ tipsï¼Œä½¿ç”¨ SDK çš„ç»“æžœ
            toastViewTips = ""

            if newValue == VerifyResultCode.COLOR_LIVENESS_LIGHT_TOO_HIGH{
                withAnimation { //å…‰çº¿å¤ªå¼ºäº†
                    showLightHighDialog = true
                }
            }else{
                showToast = true
                print("æ£€æµ‹è¿”å›ž ï¼š \(viewModel.faceVerifyResult)")

                // âœ… Capture attendance image if verification successful
                // Check if verification passed (similarity > threshold)
                if viewModel.faceVerifyResult.similarity > threshold {
                    print("âœ… Verification SUCCESS - attempting to capture attendance image...")
                    print("ðŸ“Š Similarity: \(viewModel.faceVerifyResult.similarity) > Threshold: \(threshold)")

                    // Try to capture frame for attendance
                    // Note: This requires SDK to expose captured frame
                    // For now, we attempt capture but SDK may not provide image
                    captureAttendanceImage()

                    // TODO: If SDK provides captured UIImage in faceVerifyResult,
                    // store it here using AttendanceImageHelper
                    // Example:
                    // if let capturedImage = viewModel.faceVerifyResult.capturedImage {
                    //     AttendanceImageHelper.shared.storeTempImage(capturedImage)
                    //     print("âœ… Stored captured image for attendance")
                    // }
                }

                DispatchQueue.main.asyncAfter(deadline: .now() + 1) {
                    withAnimation {
                        showToast = false
                    }
                    onDismiss(viewModel.faceVerifyResult.code)
                    dismiss()
                }
            }
        }
        .onDisappear {
            if autoControlBrightness {
                ScreenBrightnessHelper.shared.restoreBrightness()
            }
            
            viewModel.stopFaceVerify()
        }
        .animation(.easeInOut(duration: 0.3), value: showToast)
    }
}
